==========================================================================================
[강화학습 주식투자 추가 내용]

Tf로 바꾸기
네트워크 수정 및 추가

팩터 추가
매매 수수료 및 세금 추가
정책 신경망 출력 결과의 확률 중 max값을 선택해도 그 확률 자체가 낮을 수도 있으므로 일정 확률 이상의 값이 되어야만 그 max 값을 선택

지도 학습은 추세 학습 못하는 듯(확인) - 강화학습은?    비지도학습은?


self Q. 알파고가 스스로 자신(다른 알파고)와 경쟁하며 학습력을 향상시키듯이 RA 알고리즘(모델)도 서로 경쟁하며 발전할 수 있을까? (같은 알고리즘(모델)간 경쟁 & 다른 알고리즘(모델)간 경쟁)

("KDB대우증권 관계자는 “무궁무진한 퀀트베이스가 바탕”이라며 “알고리즘이 경쟁하는 플랫폼 구축을 통해 투자자가 자기성향에 맞는 알고리즘을 선택하고 자동으로 포트폴리오를 리벨런싱한다는 점에서 시스템트레이딩보다 진일보한 서비스”라고 설명했다. 한때 특허받은 ETF자동매매시스템인 스마트인베스터로 시스템트레이딩붐을 일으켰던 NH투자증권도 마찬가지. NH투자증권 관계자는 “시스템트레이딩 변형한 형태로 다양한 알고리즘을 통해 자기투자성향에 맞는 최적화된 자산배분이나 투자전략을 짤 수 있는 것이 장점”이라며 “포괄적인 자산관리의 툴로 확대하고 있다”라고 말했다. 한편 로보어드바이저의 성공가능성에 대해 기대와 우려가 엇갈린다. [http://www.fntimes.com/html/view.php?ud=141741]


selfQ. 이런저런 데이터와 알고리즘을 가져와서 예측을 한다고해도 시장의 Madness를 감안하지 않는 이상 더 이상 발전 불가하다고 생각 --> Madness를 측정하고 알고리즘에 반영할 수 있는 방법?

==========================================================================================



P.73: 에이전트 상태 다양화

P.74: 거래 횟수 변경 및 수수료와 세금 추가

P.74: 관망이 유리한 상황 계산에 대한 확인 필요

P.75: 행동에 대한 확신과 지연 보상 임계치 변경 

P.76: 학습 단계에서 한 에포크마다 에이전트의 상태 초기화해야함 --> Why?

P.77: 투자 행동 결정에 영향을 주는 것이 (그래서 정책 신경망의 입력에 포함할만한 것이) 또 뭐가 있을까?

P.79: 신용 매수 및 공매도 고려

P.80: 확률에 따른 매수/매도 행동 단위 결정하는 식 이해 불가

P.81: 좋은 식(알고리즘) --> 주석 보고 다시 이해해 볼 것

P.87: 여러 학습 알고리즘 및 방법 적용해 볼 것

P.88: 코드 보면 왜 2차원으로 안하고 3차원으로 한건가? 그리고 괄호는 왜 2개야? --> 케라스에서 필요로하는 성질에 따른 것인가?

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.:

P.: 